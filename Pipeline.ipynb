{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc49dd8e",
   "metadata": {},
   "source": [
    "# Pipeline For Computing Complete Payload Data\n",
    "\n",
    "This pipeline is created for the ease of users willing to generate the complete data on their own. There are few things that should be kept in mind before executing this. \n",
    "\n",
    ">1. You should have enough space in your hard drive before executing this notebook. Approximately you should have atleast 400GB of space for storing and saving results of PCAP files.\n",
    ">2. This notebook is compatible with python version 3.7.13. \n",
    ">3. Developed parser is based on Scapy module. Make sure it is installed. \n",
    ">4. Code processing might requrie high RAM space, therefore if you are on low resources try other method. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f76711f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/scapy/layers/ipsec.py:471: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  cipher=algorithms.Blowfish,\n",
      "/opt/conda/lib/python3.9/site-packages/scapy/layers/ipsec.py:485: CryptographyDeprecationWarning: CAST5 has been deprecated\n",
      "  cipher=algorithms.CAST5,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from Functions.Pipeline import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5213dc11",
   "metadata": {},
   "source": [
    "#### There are three inputs for the pipeline:\n",
    "\n",
    ">1. In_directory (in_dir) = The directory where PCAP files are stored. For UNSW there are two folders wheras for CICIDS there are five individual files.\n",
    ">2. Out_directory (out_dir) = The directory where you want the outcome of the tool to be stored.\n",
    ">3. Dataset Name= `UNSW` or `CICIDS`.\n",
    ">4. Processed CSV File = The directory for combined and processed CSV file. For processing the CSV files navigate to `CSV_data_preprocessing` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f375feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = \"/home/jovyan/wire/DataSets/UNSW-NB15/UNSW-NB15 - pcap files\"\n",
    "out_dir = \"/home/jovyan/UNSW_results\"\n",
    "Dataset_name = \"UNSW\"\n",
    "processed_csv_file = \"/home/jovyan/payload-byte-data/UNSW-NB15_processed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a1d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 15:40:24,015 - INFO -Checking directory for files ......\n",
      "2022-10-27 15:40:24,015 - INFO -Files found. Initiating PCAP Parsing.......\n",
      "2022-10-27 15:40:24,016 - INFO -Parsing 22-1-2015 Files .........\n",
      "2022-10-27 15:40:24,016 - INFO -Reading input file:  /home/jovyan/wire/DataSets/UNSW-NB15/UNSW-NB15 - pcap files/pcaps 22-1-2015/1.pcap\n",
      "2022-10-27 15:40:46,275 - INFO -Done with 100000 Packets\n",
      "2022-10-27 15:41:08,858 - INFO -Done with 200000 Packets\n",
      "2022-10-27 15:41:31,533 - INFO -Done with 300000 Packets\n",
      "2022-10-27 15:41:54,195 - INFO -Done with 400000 Packets\n",
      "2022-10-27 15:42:17,226 - INFO -Done with 500000 Packets\n",
      "2022-10-27 15:42:39,544 - INFO -Done with 600000 Packets\n",
      "2022-10-27 15:43:02,553 - INFO -Done with 700000 Packets\n",
      "2022-10-27 15:43:24,965 - INFO -Done with 800000 Packets\n",
      "2022-10-27 15:43:48,095 - INFO -Done with 900000 Packets\n",
      "2022-10-27 15:44:11,671 - INFO -Done with 1000000 Packets\n",
      "2022-10-27 15:44:34,701 - INFO -Done with 1100000 Packets\n",
      "2022-10-27 15:44:58,401 - INFO -Done with 1200000 Packets\n",
      "2022-10-27 15:45:21,073 - INFO -Done with 1300000 Packets\n",
      "2022-10-27 15:45:43,908 - INFO -Done with 1400000 Packets\n",
      "WARNING: DNS decompression loop detected\n",
      "2022-10-27 15:45:45,463 - WARNING -DNS decompression loop detected\n",
      "WARNING: DNS decompression loop detected\n",
      "2022-10-27 15:45:45,478 - WARNING -DNS decompression loop detected\n",
      "2022-10-27 15:46:07,756 - INFO -Done with 1500000 Packets\n",
      "WARNING: DNS decompression loop detected\n",
      "2022-10-27 15:46:13,970 - WARNING -DNS decompression loop detected\n",
      "WARNING: DNS decompression loop detected\n",
      "2022-10-27 15:46:13,972 - WARNING -DNS decompression loop detected\n",
      "2022-10-27 15:46:30,265 - INFO -Done with 1600000 Packets\n",
      "2022-10-27 15:46:52,704 - INFO -Done with 1700000 Packets\n",
      "2022-10-27 15:47:16,526 - INFO -Done with 1800000 Packets\n",
      "2022-10-27 15:47:16,679 - INFO -Done reading /home/jovyan/wire/DataSets/UNSW-NB15/UNSW-NB15 - pcap files/pcaps 22-1-2015/1.pcap\n",
      "/home/jovyan/payload-byte-public/Functions/Optimized_Parser_Labelling.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out.t_delta[0] = 0\n",
      "2022-10-27 15:47:26,909 - INFO -Exporting CSV File#1\n",
      "2022-10-27 15:47:53,601 - INFO -Reading input file:  /home/jovyan/wire/DataSets/UNSW-NB15/UNSW-NB15 - pcap files/pcaps 22-1-2015/2.pcap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tcp     1772972\n",
      "udp       27125\n",
      "ospf        254\n",
      "arp         254\n",
      "icmp         69\n",
      "sctp          4\n",
      "igmp          2\n",
      "Name: protocol_m, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 15:48:16,593 - INFO -Done with 100000 Packets\n",
      "2022-10-27 15:48:39,364 - INFO -Done with 200000 Packets\n",
      "2022-10-27 15:49:02,368 - INFO -Done with 300000 Packets\n",
      "2022-10-27 15:49:25,836 - INFO -Done with 400000 Packets\n",
      "2022-10-27 15:49:49,351 - INFO -Done with 500000 Packets\n",
      "2022-10-27 15:50:13,034 - INFO -Done with 600000 Packets\n",
      "2022-10-27 15:50:35,672 - INFO -Done with 700000 Packets\n",
      "2022-10-27 15:50:58,710 - INFO -Done with 800000 Packets\n",
      "2022-10-27 15:51:22,218 - INFO -Done with 900000 Packets\n",
      "2022-10-27 15:51:44,882 - INFO -Done with 1000000 Packets\n",
      "2022-10-27 15:52:07,487 - INFO -Done with 1100000 Packets\n",
      "2022-10-27 15:52:31,129 - INFO -Done with 1200000 Packets\n",
      "2022-10-27 15:52:53,721 - INFO -Done with 1300000 Packets\n",
      "2022-10-27 15:53:17,413 - INFO -Done with 1400000 Packets\n",
      "2022-10-27 15:53:39,841 - INFO -Done with 1500000 Packets\n",
      "2022-10-27 15:54:02,438 - INFO -Done with 1600000 Packets\n",
      "2022-10-27 15:54:05,829 - INFO -Done reading /home/jovyan/wire/DataSets/UNSW-NB15/UNSW-NB15 - pcap files/pcaps 22-1-2015/2.pcap\n",
      "/home/jovyan/payload-byte-public/Functions/Optimized_Parser_Labelling.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out.t_delta[0] = 0\n",
      "2022-10-27 15:54:16,096 - INFO -Exporting CSV File#2\n",
      "2022-10-27 15:54:43,470 - INFO -Reading input file:  /home/jovyan/wire/DataSets/UNSW-NB15/UNSW-NB15 - pcap files/pcaps 22-1-2015/3.pcap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tcp       1589743\n",
      "udp         24668\n",
      "ospf          304\n",
      "arp           188\n",
      "icmp           54\n",
      "pim             8\n",
      "sctp            6\n",
      "igmp            4\n",
      "sep             2\n",
      "swipe           1\n",
      "mobile          1\n",
      "sun-nd          1\n",
      "Name: protocol_m, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 15:55:06,733 - INFO -Done with 100000 Packets\n",
      "2022-10-27 15:55:29,819 - INFO -Done with 200000 Packets\n",
      "2022-10-27 15:55:52,819 - INFO -Done with 300000 Packets\n",
      "2022-10-27 15:56:15,904 - INFO -Done with 400000 Packets\n",
      "2022-10-27 15:56:39,011 - INFO -Done with 500000 Packets\n",
      "2022-10-27 15:57:02,206 - INFO -Done with 600000 Packets\n",
      "2022-10-27 15:57:24,819 - INFO -Done with 700000 Packets\n",
      "2022-10-27 15:57:48,205 - INFO -Done with 800000 Packets\n",
      "2022-10-27 15:58:10,846 - INFO -Done with 900000 Packets\n",
      "2022-10-27 15:58:34,513 - INFO -Done with 1000000 Packets\n",
      "2022-10-27 15:58:57,178 - INFO -Done with 1100000 Packets\n",
      "2022-10-27 15:59:19,891 - INFO -Done with 1200000 Packets\n",
      "2022-10-27 15:59:43,604 - INFO -Done with 1300000 Packets\n",
      "2022-10-27 16:00:06,284 - INFO -Done with 1400000 Packets\n",
      "2022-10-27 16:00:28,983 - INFO -Done with 1500000 Packets\n",
      "2022-10-27 16:00:53,114 - INFO -Done with 1600000 Packets\n"
     ]
    }
   ],
   "source": [
    "df = pipeline(in_dir, out_dir, Dataset_name, processed_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "394d4042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal            6681484\n",
       "generic             16829\n",
       "exploits            13166\n",
       "fuzzers             11898\n",
       "reconnaissance       6812\n",
       "dos                  2571\n",
       "shellcode            1088\n",
       "backdoor              519\n",
       "analysis              383\n",
       "worms                  93\n",
       "Name: attack_cat, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.attack_cat.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f434cc2",
   "metadata": {},
   "source": [
    "## Undersampling Normal Data Instances\n",
    "\n",
    "Since number of normal data instances are extensively higher than the attacks, normal instances are undersampled as mentioned in the paper. If you dont want to reduce the data instances ignore this step.\n",
    "\n",
    "Or if you want to reduce it according to your approach change the data instances provided in `dict`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For UNSW\n",
    "dict = {\n",
    "    \"generic\": 17580,\n",
    "    \"exploits\": 13992,\n",
    "    \"fuzzers\": 12722,\n",
    "    \"reconnaissance\": 7562,\n",
    "    \"dos\": 3397,\n",
    "    \"backdoor\": 1239,\n",
    "    \"analysis\": 1208,\n",
    "    \"shellcode\": 1088,\n",
    "    \"normal\": 21000,\n",
    "    \"worms\": 93,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dfdb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For CICIDS\n",
    "dict = {\n",
    "    \"BENIGN\": 362108,\n",
    "    \"DoS Hulk\": 250000,\n",
    "    \"DDoS\": 241405,\n",
    "    \"DoS GoldenEye\": 128122,\n",
    "    \"DoS slowloris\": 121097,\n",
    "    \"Infiltration\": 115007,\n",
    "    \"DoS Slowhttptest\": 80542,\n",
    "    \"SSH-Patator\": 48165,\n",
    "    \"FTP-Patator\": 31843,\n",
    "    \"Heartbleed\": 13486,\n",
    "    \"Web Attack – Brute Force\": 11754,\n",
    "    \"Web Attack – XSS\": 3341,\n",
    "    \"Bot\": 2543,\n",
    "    \"PortScan\": 830,\n",
    "    \"Web Attack – Sql Injection\": 12,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34081712",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res = df.iloc[:, :-1]\n",
    "y_res = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe8f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=dict)\n",
    "X_res, y_res = rus.fit_resample(df.iloc[:, :-1], df.iloc[:, -1])\n",
    "X_res[\"label\"] = y_res\n",
    "df = 0\n",
    "df = X_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b35b76d",
   "metadata": {},
   "source": [
    "## Transformation of Hex Valued Payload into Byte-Wise Integers\n",
    "\n",
    "Transform data into 1504 features, following the employed feature vector as explained in the paper.\n",
    "Each feature is in integer form and can be utilized for training of Machine Learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc21832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out_dir => directory for saving the transformed data\n",
    "out_dir = \"D:/UNSW_results/\"\n",
    "\n",
    "df_t = transform(df, out_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
