{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc49dd8e",
   "metadata": {},
   "source": [
    "# Pipeline For Computing Complete Payload Data\n",
    "\n",
    "This pipeline is created for the ease of users willing to generate the complete data on their own. There are few things that should be kept in mind before executing this. \n",
    "\n",
    ">1. You should have enough space in your hard drive before executing this notebook. Approximately you should have atleast 400GB of space for storing and saving results of PCAP files.\n",
    ">2. This notebook is compatible with python version 3.7.13. \n",
    ">3. Developed parser is based on Scapy module. Make sure it is installed. \n",
    ">4. Code processing might requrie high RAM space, therefore if you are on low resources try other method. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f76711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from functions.Pipeline import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5213dc11",
   "metadata": {},
   "source": [
    "#### There are three inputs for the pipeline:\n",
    "\n",
    ">1. In_directory (in_dir) = The directory where PCAP files are stored. For UNSW there are two folders wheras for CICIDS there are five individual files.\n",
    ">2. Out_directory (out_dir) = The directory where you want the outcome of the tool to be stored.\n",
    ">3. Dataset Name= `UNSW` or `CICIDS`.\n",
    ">4. Processed CSV File = The directory for combined and processed CSV file. For processing the CSV files navigate to `CSV_data_preprocessing` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f375feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir='D:/UNSW'\n",
    "out_dir=\"D:/UNSW_results\"\n",
    "Dataset_name='UNSW'\n",
    "processed_csv_file=\"E:/UNSW-NB15 Dataset/UNSW-NB15-CSV-Files/Preprocessed-CSV/UNSW-NB15_processed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a1d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pipeline(in_dir,out_dir,Dataset_name,processed_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d4042",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.attack_cat.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f434cc2",
   "metadata": {},
   "source": [
    "## Undersampling Normal Data Instances\n",
    "\n",
    "Since number of normal data instances are extensively higher than the attacks, normal instances are undersampled as mentioned in the paper. If you dont want to reduce the data instances ignore this step.\n",
    "\n",
    "Or if you want to reduce it according to your approach change the data instances provided in `dict`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For UNSW\n",
    "dict={ 'generic':17580,\n",
    "'exploits':13992,\n",
    "'fuzzers'  : 12722,\n",
    "'reconnaissance': 7562,\n",
    "'dos'  : 3397,\n",
    "'backdoor' :   1239,\n",
    "'analysis' :  1208,\n",
    "'shellcode': 1088,\n",
    "'normal': 21000,\n",
    "'worms':  93\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dfdb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For CICIDS\n",
    "dict={ 'BENIGN': 362108,\n",
    "'DoS Hulk':          250000,\n",
    "'DDoS'  :         241405,\n",
    "'DoS GoldenEye':     128122,\n",
    "'DoS slowloris':    121097,\n",
    "'Infiltration'        :115007,\n",
    "'DoS Slowhttptest'         :  80542,\n",
    "'SSH-Patator':          48165,\n",
    "'FTP-Patator'            :   31843,\n",
    "'Heartbleed'              :  13486,\n",
    "'Web Attack – Brute Force'            :   11754,\n",
    "'Web Attack – XSS'              :  3341,\n",
    "'Bot'            :   2543,\n",
    "'PortScan'              :  830,\n",
    "'Web Attack – Sql Injection': 12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34081712",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res=df.iloc[:,:-1]\n",
    "y_res=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe8f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42,sampling_strategy=dict)\n",
    "X_res, y_res = rus.fit_resample(df.iloc[:,:-1], df.iloc[:,-1])\n",
    "X_res['label']=y_res\n",
    "df=0\n",
    "df=X_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b35b76d",
   "metadata": {},
   "source": [
    "## Transformation of Hex Valued Payload into Byte-Wise Integers\n",
    "\n",
    "Transform data into 1504 features, following the employed feature vector as explained in the paper.\n",
    "Each feature is in integer form and can be utilized for training of Machine Learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc21832a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Out_dir => directory for saving the transformed data\n",
    "out_dir=\"D:/UNSW_results/\"\n",
    "\n",
    "df_t=transform(df,out_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
